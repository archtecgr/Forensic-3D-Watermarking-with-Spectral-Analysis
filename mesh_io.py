"""
mesh_io.py
Mesh file I/O — supports OBJ and STL (ASCII & binary).
"""

import numpy as np
import struct
from pathlib import Path


def load_mesh(filepath: str) -> tuple[np.ndarray, np.ndarray]:
    """
    Load a mesh file. Returns (vertices, faces).
    Supports: .obj, .stl (ASCII and binary).
    """
    path = Path(filepath)
    ext = path.suffix.lower()
    if ext == ".obj":
        return _load_obj(path)
    elif ext == ".stl":
        return _load_stl(path)
    else:
        raise ValueError(f"Unsupported file format: {ext}. Use .obj or .stl")


def save_mesh(filepath: str, vertices: np.ndarray, faces: np.ndarray) -> None:
    """Save mesh to file. Format determined by extension."""
    path = Path(filepath)
    ext = path.suffix.lower()
    if ext == ".obj":
        _save_obj(path, vertices, faces)
    elif ext == ".stl":
        _save_stl_binary(path, vertices, faces)
    else:
        raise ValueError(f"Unsupported file format: {ext}. Use .obj or .stl")


# ─── OBJ ─────────────────────────────────────────────────────────────────────

def _load_obj(path: Path) -> tuple[np.ndarray, np.ndarray]:
    vertices = []
    faces = []
    with open(path, "r") as f:
        for line in f:
            line = line.strip()
            if line.startswith("v "):
                parts = line.split()
                vertices.append([float(parts[1]), float(parts[2]), float(parts[3])])
            elif line.startswith("f "):
                parts = line.split()[1:]
                # OBJ faces can be "v", "v/vt", "v/vt/vn", "v//vn"
                face = []
                for p in parts:
                    idx = int(p.split("/")[0]) - 1  # 1-indexed
                    face.append(idx)
                # Triangulate fan style if polygon
                for i in range(1, len(face) - 1):
                    faces.append([face[0], face[i], face[i + 1]])
    return np.array(vertices, dtype=np.float64), np.array(faces, dtype=np.int64)


def _save_obj(path: Path, vertices: np.ndarray, faces: np.ndarray) -> None:
    with open(path, "w") as f:
        f.write("# Generated by Forensic 3D Watermarking Suite\n")
        for v in vertices:
            f.write(f"v {v[0]:.10f} {v[1]:.10f} {v[2]:.10f}\n")
        for face in faces:
            f.write(f"f {face[0]+1} {face[1]+1} {face[2]+1}\n")


# ─── STL ─────────────────────────────────────────────────────────────────────

def _is_binary_stl(path: Path) -> bool:
    """Heuristic: binary STL has 80-byte header + 4-byte face count."""
    size = path.stat().st_size
    with open(path, "rb") as f:
        f.seek(80)
        if size < 84:
            return False
        num_faces = struct.unpack("<I", f.read(4))[0]
        expected_size = 84 + num_faces * 50
        return size == expected_size


def _load_stl(path: Path) -> tuple[np.ndarray, np.ndarray]:
    if _is_binary_stl(path):
        return _load_stl_binary(path)
    else:
        return _load_stl_ascii(path)


def _load_stl_ascii(path: Path) -> tuple[np.ndarray, np.ndarray]:
    vertices = []
    faces = []
    vert_buffer = []
    with open(path, "r") as f:
        for line in f:
            line = line.strip()
            if line.startswith("vertex"):
                parts = line.split()
                vert_buffer.append([float(parts[1]), float(parts[2]), float(parts[3])])
            elif line.startswith("endloop"):
                if len(vert_buffer) == 3:
                    base = len(vertices)
                    vertices.extend(vert_buffer)
                    faces.append([base, base + 1, base + 2])
                vert_buffer = []
    verts, faces_arr = _deduplicate_stl_vertices(
        np.array(vertices, dtype=np.float64),
        np.array(faces, dtype=np.int64)
    )
    return verts, faces_arr


def _load_stl_binary(path: Path) -> tuple[np.ndarray, np.ndarray]:
    vertices = []
    faces = []
    with open(path, "rb") as f:
        f.read(80)  # header
        num_faces = struct.unpack("<I", f.read(4))[0]
        for _ in range(num_faces):
            f.read(12)  # normal (skip)
            tri_verts = []
            for _ in range(3):
                v = struct.unpack("<fff", f.read(12))
                tri_verts.append(list(v))
            base = len(vertices)
            vertices.extend(tri_verts)
            faces.append([base, base + 1, base + 2])
            f.read(2)  # attribute byte count
    verts, faces_arr = _deduplicate_stl_vertices(
        np.array(vertices, dtype=np.float64),
        np.array(faces, dtype=np.int64)
    )
    return verts, faces_arr


def _deduplicate_stl_vertices(
    vertices: np.ndarray,
    faces: np.ndarray,
    tolerance: float = 1e-8
) -> tuple[np.ndarray, np.ndarray]:
    """Merge vertices that are within tolerance — critical for STL which has no shared indices."""
    from scipy.spatial import cKDTree
    tree = cKDTree(vertices)
    # Find clusters
    unique_indices = []
    old_to_new = np.zeros(len(vertices), dtype=np.int64)
    visited = np.zeros(len(vertices), dtype=bool)

    for i in range(len(vertices)):
        if visited[i]:
            continue
        neighbors = tree.query_ball_point(vertices[i], tolerance)
        new_idx = len(unique_indices)
        unique_indices.append(i)
        for n in neighbors:
            old_to_new[n] = new_idx
            visited[n] = True

    new_verts = vertices[unique_indices]
    new_faces = old_to_new[faces]
    return new_verts, new_faces


def _save_stl_binary(path: Path, vertices: np.ndarray, faces: np.ndarray) -> None:
    with open(path, "wb") as f:
        f.write(b"\x00" * 80)  # header
        f.write(struct.pack("<I", len(faces)))
        for face in faces:
            v0, v1, v2 = vertices[face[0]], vertices[face[1]], vertices[face[2]]
            normal = np.cross(v1 - v0, v2 - v0)
            n = np.linalg.norm(normal)
            if n > 1e-12:
                normal /= n
            f.write(struct.pack("<fff", *normal))
            f.write(struct.pack("<fff", *v0))
            f.write(struct.pack("<fff", *v1))
            f.write(struct.pack("<fff", *v2))
            f.write(struct.pack("<H", 0))
